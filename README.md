# ğŸ§‘â€ğŸ’» Person and Character Wiki Bot

A modular, full-stack RAG (Retrieval-Augmented Generation) assistant for exploring and chatting about Wikipedia or Fandom pages of fictional characters and real people.  
Supports both file upload (offline) and online scraping, and adapts for any structured Wiki/biographical HTML.

---

## âœ¨ Features

- **ğŸ¤– Smart LLM Chat & Facts:**
    - Ask any question about the loaded person or characterâ€”bot answers contextually using automatically extracted facts!
    - Combines open-source local sentence embeddings with Perplexity API for robust retrieval and reasoning.

- **ğŸ”„ Two Processing Modes:**
    - ğŸ“ Upload a saved HTML page from any Wikipedia, Fandom, or biographical site (*right-click â†’ Save As...*)
    - ğŸŒ Enter a live Wiki URL (scrape online, if allowedâ€”may be blocked)

- **ğŸ–¥ï¸ Gradio Web Interface:**
    - Clean, tabbed UI for profile input and conversational Q&A

---

## ğŸš€ Quickstart

1. **Clone and install**
    ```
    git clone https://github.com/YOUR_USERNAME/person-character-wiki-bot
    cd person-character-wiki-bot
    pip install -r requirements.txt
    ```
2. **Set up your `.env`**
    ```
    PPLX_API_KEY=sk-xxxxxxx...
    ```
3. **Launch!**
    ```
    python app_wiki.py
    # â†’ Open http://localhost:5001 in your browser
    ```

---

## ğŸ› ï¸ How It Works

- **Step 1: Choose a Mode**
    - ğŸ“ *Upload HTML*: Great for JS-heavy or anti-bot protected pagesâ€”works offline!
    - ğŸŒ *Wiki URL/Mock*: Live scraping (if allowed) or repeatable mock test

- **Step 2:** The system parses/splits HTML, builds vector index with local embeddings

- **Step 3:** LLM summarizes interesting facts

- **Step 4:** ğŸ—£ï¸ Chat with the bot for context-aware Q&A

#### Tech Stack

- **Python**
- **Gradio** (`Blocks`, `Chatbot`)
- **LlamaIndex** (`VectorStoreIndex`, node splitting, prompts)
- **Perplexity API** (LLM with temperature/token controls)
- **HuggingFace Embeddings**
- **BeautifulSoup**
- **Modular design** for easy extension

---

## ğŸ’¡ Usage Notes

- âœ¨ **Upload HTML File** for the most reliable results (offline-ready, bypasses anti-bot)
- ğŸ” Web scraping may hit 403/empty results on some sites with strict protection
- ğŸŒ LLM API usage is subject to rate limits if using hosted models

---
## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+, < 3.13
- A Perplexity API key (recommended for full features â€” mock/HTML upload available without)

### Installation

1. Clone the repository:
    ```
    git clone https://github.com/vuqu-git/person-character-wiki-bot.git
    cd person-character-wiki-bot
    ```

2. Create a virtual environment:
    ```
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3. Install dependencies:
    ```
    pip install -r requirements.txt
    ```

4. Add your Perplexity API key to `.env`:
    ```
    PPLX_API_KEY=sk-xxxxxxx...
    ```

### Using the Web Interface

Launch the web app:

    python main.py --mock


Then open your browser to the displayed local URL (typically http://127.0.0.1:5001).

### Using the Command Line Interface (optional, if implemented)

Use mock HTML (file upload) mode

    python main.py --mock
OR use live wiki scraping (if supported by site)

    python main.py --url "https://en.wikipedia.org/wiki/Aloy"


---

## ğŸ§  How It Works

This bot uses a Retrieval-Augmented Generation (RAG) pipeline tailored for Wiki/biographical data:

1. **Data Extraction**: Profile HTML is scraped or loaded from file
2. **Text Processing**: Content is split into semantic nodes by section/paragraph
3. **Vector Embedding**: Nodes are embedded using open-source HuggingFace models
4. **Storage**: Embeddings are stored in a vector database for context retrieval
5. **Query & Generation**: When you ask a question or request facts, top nodes are retrieved and a Perplexity LLM generates contextually accurate responses


---

## ğŸ§ª Customization

### Using Different LLM Models

Edit `config.py` or update environment variables to swap models or adjust generation parameters.

### Adjusting Fact/Answer Style

Tweak the prompt templates in `config.py` to modify how facts or answers are generated:

    INITIAL_FACTS_TEMPLATE = """
    You are an AI assistant that provides detailed answers based on the provided context...
    """